{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "289cb790",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1231a8c",
   "metadata": {},
   "source": [
    "# Graded Assignment: Classification in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e384c70d",
   "metadata": {},
   "source": [
    "Kuis ini merupakan bagian dari proses penilaian Algoritma Training. Selamat atas selesainya materi Classification dalam Machine Learning. Kami akan melakukan penilaian berupa kuis untuk menguji praktek teknik pembuatan model regresi dan klasifikasi yang sudah Anda pelajari.\n",
    "\n",
    "Pada quiz berikut, Anda akan diminta membuat model klasifikasi sebagai penilaian pemahaman mengenai materi yang sudah dipelajari sebelumnya."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04960383",
   "metadata": {},
   "source": [
    "## Credit Risk Analysis\n",
    "\n",
    "Ketika bank menerima permohonan pinjaman, berdasarkan profil pemohon maka bank harus membuat keputusan apakah akan melanjutkan persetujuan pinjaman atau tidak. Dua jenis resiko terkait keputusan bank: \n",
    "\n",
    "- Jika pemohon memiliki risiko kredit yang baik, yaitu mungkin untuk membayar kembali pinjaman, maka tidak menyetujui pinjaman kepada orang tersebut mengakibatkan kerugian bisnis bagi bank\n",
    "- Jika pemohon memiliki risiko kredit yang buruk, yaitu tidak mungkin untuk membayar kembali pinjaman, maka menyetujui pinjaman kepada orang tersebut mengakibatkan kerugian finansial bagi bank."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98829301",
   "metadata": {},
   "source": [
    "### Import data\n",
    "\n",
    "Kali ini kita akan menggunakan data `credit_germany.csv` yang tersimpan pada folder `data_input`. Data ini merupakan data real dari suatu bank yang ada di German."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0945488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "##  code here\n",
    "# credit = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f58319",
   "metadata": {},
   "source": [
    "**Data Description:**\n",
    "\n",
    "- `Creditability` : Apakah peminjam memiliki risiko kredit yang buruk (0) atau kredit baik (1)\n",
    "- `Account_Balance` : Kategori apakah peminjam memiliki akun bank\n",
    "    - No account = tidak memiliki akun bank\n",
    "    - Have account = memiliki akun dan balance pada bank\n",
    "- `Duration_of_Credit_monthly` : Durasi pinjaman dalam bulan\n",
    "- `Payment_Status_of_Previous_Credit` : Histori pembayaran dari kredit yang pernah diajukan sebelumnya\n",
    "    - No_loan_history = Tidak memiliki riwayat pinjaman\n",
    "    - Some_Problems = Terlambat bayar dan belum diselesaikan pembayarannya \n",
    "    - Paid_Up = Pernah terlambat bayar dan sudah diselesaikan pembayarannya \n",
    "    - No_Problems = Tidak ada masalah\n",
    "- `Credit_Amount` : Jumlah nominal pinjaman yang diajukan\n",
    "- `Length_of_current_employment` : Lama bekerja di tempat kerja sekarang dalam tahun\n",
    "- `Guarantors` : Apakah terdapat penjamin pinjaman atau tidak\n",
    "    - No = Tidak ada penjamin\n",
    "    - Yes =  Ada penjamin\n",
    "- `Duration_in_Current_address` : Durasi lama tinggal di tempat tinggal sekarang dalam tahun\n",
    "- `Age_years` : Usia peminjam\n",
    "- `Concurrent_Credits`: Tipe kredit yang sedang berjalan bersamaan\n",
    "    - No_credit = Tidak ada kredit yang jalan bersamaan \n",
    "    - Dept_Stores = Credit terhadap department store \n",
    "    - Other_Bank = Credit terhadap bank lain\n",
    "- `No_of_Credits_at_this_Bank`: Jumlah kredit yang sedang berjalan pada bank ini\n",
    "\n",
    "Sebelum masuk pada tahap pembuatan model, kita akan melakukan EDA untuk mengetahui variabel prediktor yang perlu dimasukkan dalam model dan yang tidak.\n",
    "\n",
    "### Wrangling Data\n",
    "\n",
    "#### Mengubah tipe data\n",
    "\n",
    "Sebelum melakukan perubahan tipe data, silakan cek terlebih dahulu jenis tipe datanya dengan menggunakan method `dtypes`/`info()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ddfe74b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # list berisi nama kolom yang ingin diubah dalam format sama\n",
    "# cat = \n",
    "\n",
    "# # Mengubah tipe data beberapa kolom\n",
    "# credit[cat] = credit[cat].astype(______)\n",
    "\n",
    "# # cek kembali tipe data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f2b0ec",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "Mari lakukan analisis korelasi antar kolom numerik pada dataset kita. Sebelumnya, pastikan bahwa Anda telah memilih kolom-kolom yang bersifat numerik untuk dimasukkan dalam perhitungan korelasi. \n",
    "\n",
    "Proses ini akan membantu kita memahami hubungan statistik antara variabel-variabel numerik dalam dataset, sehingga kita dapat mendapatkan wawasan yang lebih mendalam terkait dengan pola atau asosiasi yang mungkin ada di antara mereka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "907770e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# credit.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7496797",
   "metadata": {},
   "source": [
    "**Soal 1: Mana dari berikut ini adalah pasangan variabel dengan korelasi tertinggi?**\n",
    "\n",
    "- [ ] A. `Duration_of_Credit_monthly` dan `Credit_Amount`\n",
    "- [ ] B. `Credit_Amount` dan `Length_of_current_employment`\n",
    "- [ ] C. `Duration_in_Current_address` dan `No_of_Credits_at_this_Bank`\n",
    "- [ ] D. `Age_years` dan `No_of_Credits_at_this_Bank`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1143d1",
   "metadata": {},
   "source": [
    "###  Data Pre-Processing\n",
    "\n",
    "Terdapat 2 hal yang biasanya dilakukan pada tahapan data pre-processing yaitu **Dummy Variable Encoding** dan juga **Cross Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de55b0f4",
   "metadata": {},
   "source": [
    "####  Dummy Variable Encoding \n",
    "\n",
    "Variabel yang kita miliki terdapat variabel dengan tipe data category, oleh karena itu kita perlu membuat dummy variabel terlebih dahulu. Untuk algoritma Logistic Regression, karena masih terdapat asumsi multicolinearity, maka yang akan dipakai adalah dummy variable. \n",
    "    \n",
    "Mari lakukan metode tersebut dengan memanfaatkan fungsi berikut ini `pd.get_dummies()` dan mengisinya dengan beberapa parameter antara lain:\n",
    "\n",
    "- `data`: dataset/dataframe yang ingin diubah menjadi numerikal\n",
    "- `columns`: list kolom yang akan dilakukan dummy variable encoding\n",
    "- `drop_first`: apakah ingin drop kolom pertama. Default False. Namun akan kita atur sebagai True agar kolom hasil dummies tidak redundan\n",
    "- `dtype` = memasukan tipe data yang ingin di-isi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d54af5b",
   "metadata": {},
   "source": [
    "Alasan lain kenapa kita melakukan encoding: komputer tidak mengenali bahasa natural manusia seperti bahasa Inggris, Bahasa Indonesia, dll. Komputer hanya mengenal angka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bfb786bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # code here\n",
    "# credit_enc = pd.get_dummies(data = _____, \n",
    "#                              columns = _____,\n",
    "#                              drop_first = True,\n",
    "#                              dtype =int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f188bf1",
   "metadata": {},
   "source": [
    "### Train-Test Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476464d6",
   "metadata": {},
   "source": [
    "Berikut adalah langkah-langkah yang akan kita lakukan selanjutnya dalam proses ini: \n",
    "\n",
    "Pertama, kita akan mempersiapkan data dengan menentukan variabel `X` dan `y`. \n",
    "\n",
    "Selanjutnya, kita akan melakukan train-test splitting menggunakan fungsi `train_test_split()`, di mana kita akan mengalokasikan 20% dari data sebagai data uji. Dengan ketentuan sebagai berikut:\n",
    "- **`random_state=123`** untuk memastikan reproduktivitas. \n",
    "- **`stratify = y`** untuk memastikan distribusi kelas yang seimbang dalam set data uji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bafa0083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# X = _____\n",
    "# y = _____\n",
    "\n",
    "# X_train, X_test, y_train, y_test = _____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4280d347",
   "metadata": {},
   "source": [
    "**Soal 2: Mengapa kita melakukan train-test splitting pada data?**\n",
    "\n",
    "- [ ] A. Agar model memiliki lebih banyak data untuk training\n",
    "- [ ] B. Untuk menguji model pada data yang sama dengan yang digunakan untuk pelatihan\n",
    "- [ ] C. Menghindari overfitting dan mengukur kinerja model pada data yang belum pernah dilihat\n",
    "- [ ] D. Menyederhanakan proses analisis data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5055c9",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "Setelah itu, langkah selanjutnya yang perlu diperhatikan adalah memastikan bahwa skala data yang digunakan dalam model logistik regresi seragam. Hal ini penting karena perbedaan skala pada variabel-variabel dapat memengaruhi kinerja model. \n",
    "\n",
    "Oleh karena itu, kita akan melakukan proses scaling menggunakan metode `StandarScaler()`. \n",
    "\n",
    "Pastikan untuk menggunakan metode `fit_transform` pada data pelatihan (`X_train`). Selanjutnya, kita akan menerapkan transformasi menggunakan metode `transform` pada data uji (`X_test`) \n",
    "\n",
    "Dengan cara ini, kita dapat memastikan konsistensi skala data yang digunakan oleh model logistik regresi untuk hasil yang lebih akurat dan stabil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f3f1857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c191040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transform\n",
    "# X_train_scale = _____\n",
    "# X_test_scale = _____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f86090b",
   "metadata": {},
   "source": [
    "**Soal 3: Mengapa feature scaling di scikit-learn pada data train menggunakan `fit_transform` sedangkan pada data test menggunakan `transform`?**\n",
    "\n",
    "- [ ] A. Untuk memastikan data test memiliki distribusi yang serupa dengan data train\n",
    "- [ ] B. Agar skala fitur dihitung berdasarkan data train, dan kemudian diterapkan pada data test tanpa mengubah distribusi data test\n",
    "- [ ] C. Karena transformasi yang berbeda diperlukan untuk data train dan test\n",
    "- [ ] D. Ini adalah konvensi yang umum digunakan dalam pemrosesan data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9d158b",
   "metadata": {},
   "source": [
    "### Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf6343",
   "metadata": {},
   "source": [
    "Selanjutnya, mari kita lanjutkan dengan pembuatan model regresi logistik menggunakan fungsi `LogisticRegression()`. \n",
    "\n",
    "Setelah proses tersebut, kita akan melakukan fitting model pada dataset yang telah melalui tahap scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "95c67370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # Definisikan untuk Inisialisasi model Logistic Regression.\n",
    "# class_lr = LogisticRegression()\n",
    "\n",
    "# # Fit (melatih) model dengan data pelatihan \n",
    "# class_lr.fit(_____)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf179564",
   "metadata": {},
   "source": [
    "### Model Prediction\n",
    "\n",
    "Setelah berhasil membuat model, langkah berikutnya adalah melakukan prediksi pada dataset uji (`X_test_scale`) menggunakan fungsi `predict()`. Setelah mendapatkan hasil prediksi, kita akan menampilkan proporsi kelas dari hasil prediksi tersebut menggunakan fungsi `value_counts()`. Sebelumnya, perlu dilakukan transformasi hasil prediksi menjadi objek Series menggunakan fungsi `pd.Series()`. Dengan demikian, kita dapat dengan lebih mudah menganalisis distribusi kelas pada hasil prediksi model regresi logistik tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3898cff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prediksi data\n",
    "# y_pred_class = _____\n",
    "\n",
    "# # Menampilkan distribusi kelas hasil prediksi\n",
    "# pd.Series(y_pred_class).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3084282a",
   "metadata": {},
   "source": [
    "**Soal 4: Bagaimana distribusi data hasil prediksi yang dihasilkan pada model `class_lr` kita untuk setiap kelas?**\n",
    "\n",
    "- [ ] A. Kelas 0 = 168, Kelas 1 = 32 \n",
    "- [ ] B. Kelas 0 = 182, Kelas 1 = 18\n",
    "- [ ] C. Kelas 0 = 32, Kelas 1 = 168\n",
    "- [ ] D. Kelas 0 = 18, Kelas 1 = 182"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448a7d88",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "Selain itu, untuk memastikan keefektifan dan kehandalan model yang telah dibuat, penting bagi kita untuk melakukan evaluasi model. Evaluasi ini dapat melibatkan pengukuran sejumlah metrik performa, seperti akurasi, presisi, dan recall. Untuk melakukan pengukuran ini, kita dapat memanfaatkan modul `metrics` dari pustaka scikit-learn dengan mengimpor `from sklearn import metrics`. Dengan menghitung nilai-nilai akurasi, presisi, dan recall, kita dapat memperoleh pemahaman yang lebih komprehensif tentang sejauh mana model kita dapat mengklasifikasikan data dengan benar dan efisien. Ini merupakan langkah penting dalam mengevaluasi kecanggihan model regresi logistik yang telah kita bangun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ec69e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "\n",
    "# # Menghitung akurasi\n",
    "# accuracy_lr = metrics.accuracy_score(y_test, y_pred_class)\n",
    "\n",
    "# # Menghitung presisi\n",
    "# precision_lr = metrics.precision_score(y_test, y_pred_class)\n",
    "\n",
    "# # Menghitung recall\n",
    "# recall_lr = metrics.recall_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "266fc3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(accuracy_lr)\n",
    "# print(precision_lr)\n",
    "# print(recall_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c31aa89",
   "metadata": {},
   "source": [
    "**Soal 5: Sebagai seorang yang bekerja dalam analisis risiko kredit, metrik evaluasi mana yang paling relevan untuk menilai kemampuan model dalam mendeteksi kredit yang berpotensi bermasalah?**\n",
    "\n",
    "   - [ ] A. Recall\n",
    "   - [ ] B. Specificity\n",
    "   - [ ] C. Accuracy\n",
    "   - [ ] D. Precision\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
